\documentclass{article}
\usepackage{a4wide}
\usepackage[latin1]{inputenc} %             be able to use danish letters
\usepackage[danish]{babel} %                and danish macros
\usepackage{url}                            %, hyperref} hyperref makes clickable refs.
\usepackage{amsmath}
\usepackage{listing}
\renewcommand\sfdefault{phv}%               use helvetica for sans serif
\renewcommand\familydefault{\sfdefault}%    use sans serif by default
\setlength{\parskip}{2mm plus1mm minus1mm}% a bit of (rubber) space between paragraphs

\author{}
\date{\today}
\title{Lucene\newline - introduktion og undersøgelse}

\begin{document}

\maketitle

\newpage

\tableofcontents

\newpage
\section{Om dette dokument}

Dette dokument forsøger at give et overblik over teknologierne og
mulighederne i Lucene, der er en indekserings- og søgemotor
implementeret i Java, samt de relaterede overbygningssystemer Solr og
Compass. Lucene og Solr bliver udviklet indenfor Apache Foundation
mens Compass er et selvstændig opensource projekt.

I dette dokument bruges \texttt{monospace} tekst til at angive klasser
eller programmer i de beskrevne systemer.

\section{Overblik}
Den grundlæggende funktionalitet i Lucene er analyse, indeksering og
genfinding af tekst. Lucene består af en analysedel, en indekseringsdel
og en fremsøgningsdel. Analysedelen søger - i sin mest rudimentære
form - for at dele en given tekst op i \textsf{tokens} baseret på
mellemrum (whitespace). Det er muligt at angive mere avancerede
analysemetoder, eller at skrive sine egne, ligesom det er muligt at
bruge flere analyseteknikker på en given tekst.

Indekseringen sker igennem
\texttt{Document}-klassen\footnote{\scriptsize \url{http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc/org/apache/lucene/document/Document.html}}. Et
\texttt{Document} indeholder
\texttt{Field}s\footnote{\scriptsize \url{http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc/org/apache/lucene/document/Field.html}},
der indeholder den analyserede information fra teksten.

Et \texttt{Document} bliver fysisk lagret i indeks, der oprettes (og
vedligholdes) igennem en \texttt{IndexWriter}
klasse\footnote{\scriptsize \url{http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc/org/apache/lucene/index/IndexWriter.html}}.

Søgning muliggøres igennem \texttt{QueryParser} klassen og \texttt{org.apache.lucene.search} pakken. 
%Der skal med tiden mere til dette afsnit.

\section{Analysering}
Lucene modtager udelukkende tekst der er formatteret i
\texttt{Strings}. Dette gælder for \texttt{Analyzer}-klassen såvel som
for de værdier der skrives til \texttt{Field}s i lucenes
\texttt{Document} klasse. Dette betyder at før input kan gives til
analysering i Lucene, skal det konverteres til ren tekst; noget der
kan repræsenteres i en \texttt{java.lang.String} klasse. Parsning af
tekst - eksempelvis PDF, HTML, XML, MicroSoft Word eller
lign. tekstformatteringer - skal ske inden det behandles af lucenes
analyseringsklasser. Analyseringen i Lucene opererer på teksten i form
af eksempelvis opdeling på blanktegn (whitespace) og producerer en
token-repræsentation af teksten. Teksten kan blive tokeniseret igennem
flere analyseringsmetoder, hvoraf \textit{stemming}\footnote{Lucene
  kommer med en dansk stemmer:
  \scriptsize \url{http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc/net/sf/snowball/ext/DanishStemmer.html}},
\textit{normalisering}, \textit{stopords-filtrering} og
\textit{synonym ekspansion} er de typiske i forbindelse med
analysering af fuldtekster.

\subsection{Analysering af Analyseringen}

Analysering kan være en af de større
performanceflaskehalse. Overanalyseringer af tekst er både
tidskrævende og kan have negative sideeffekter i form af reducering i
mængden af brugbar information. Det er derfor en fordel at have
testscenarier der beskriver transformationerne på teksten i hver
\texttt{Analyzer} der bliver brugt i forbindelse med
indekseringen. Lucene kommer med en pakke -
\texttt{contrib/benchmark}\footnote{\scriptsize
  \url{http://lucene.apache.org/java/2_3_2/api/org/apache/lucene/benchmark/package-summary.html} og \newline \url{http://lucene.apache.org/java/2_3_2/api/org/apache/lucene/benchmark/byTask/package-summary.html}}
- der giver mulighed for at køre forskellige standard
benchmarkalgoritmer på ens \texttt{Analyzer}.

For mindre (unit-) tests kan \texttt{Analyzer}en også kaldes direkte med tekst som input, eksempelvis som:

\begin{verbatim}
Analyzer analyzer = new StandardAnalyzer(); 
TokenStream ts = analyzer.tokenStream("myfield",new StringReader("some text goes here"));
Token t = ts.next();
while (t!=null) {
  System.out.println("token: "+t));
  t = ts.next();
}
\end{verbatim}

\subsection{Analysering og søgning}
\label{sec:anasoeg}
Eftersom \texttt{Analyzer}en deler teksten op i tokens, der
efterfølgende bliver indekseret, skal fremsøgningen af tekst helst
basere sig på samme fremgangsmåde for at kunne give meningfyldte
resultater. Som udgangspunkt skal der derfor bruges den eller de samme
\texttt{Analyzer} klasser til indeksering og søgning.

I de tilfælde hvor der skal gøres undtagelser, er det en god
tommelfingerregel kun at tilføje flere analyseringer på søgestrengene,
da \texttt{Analyzer}e typisk smider tekst | og dermed information om
indekseringen | væk. Eksempler på, hvornår det kan være en fordel at analysere mere på søgesiden end på indekseringssiden kan være:

\begin{itemize}
\item Tilføjelsen af yderligere stop-ord. 
\item Udvidelse af søgningen gennem synonymer eller ekspansion af akronymer.
\item Hvis man vil lade lucene håndtere stavekontrol gennem en \texttt{Analyzer}
\end{itemize}

\subsection{\texttt{Tokens} og afstande i indekset (\textit{proximity})}
\label{sec:proximity}
Som udgangspunkt bliver alle de analyserede \texttt{tokens} sat ind i
indekset med en afstand på 1. For en sætning "`Eksperimentet indeholdt
en test"' og et stopordsfilter der blandt andet indeholder "`en"', vil
de resulterende tokens af en analyse være "`Eksperiment"',
"`indeholdt"' og "`test"'. Med hhv. et indekseringstal på 0, 1 og
2. For søgninger der bruger proksimitet | som det er tilfældet med
\texttt{org.apache.lucene.search.spans} pakken | har dette indflydelse
på hvad eller om, der bliver returneret fra indekset (se i øvrigt
afsnit \ref{sec:searchoptions}).

\section{Indeksering}
Den overordnede struktur eller beholder for information i lucene er et
\textbf{Index}, der indeholder et eller flere \texttt{Segments}
(underindeks eller \texttt{subindex}) eller sekvenser af
\texttt{Document}s\footnote{I det følgende vil det underforstås at der
  også refereres til segmenter, når der behandles indeks}. Segmenter
fungerer som uafhængige indeks og operationer kan udføres på segmenter
uafhængigt af det indeks de er en del af.

Et \texttt{Document} indeholder sekvenser af \texttt{Fields}, der igen
indeholder sekvenser af \texttt{Terms}\footnote{\scriptsize
  \url{http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc//org/apache/lucene/index/Term.html}}. En
\texttt{Term} er et par af en \texttt{String}, der angiver navnet på
termen og en det indhold, der skal gemmes i det pågældende
\texttt{Field}.

Et \texttt{Field} gemmes i et indeks (i første omgang igennem et
\texttt{Document}) med forskellige parametre, hvoraf de centrale er:
\begin{itemize}
 \item \texttt{Field.Index}
 \item \texttt{Field.Store}
 \item \texttt{Field.TermVector}
\end{itemize}
Som nævnt ovenfor bliver et \texttt{Field} gemt med et navn og en
værdi. En værdi kan angives som et \texttt{byte} array, en
\texttt{java.lang.String}, en \texttt{java.io.Reader} eller en
\texttt{org.apache.lucene.analysis.TokenStream}. Kun hvis en værdi
bliver gemt som en \texttt{String} kan det angives, at den skal
indekseres. Derudover er det muligt at angive hvordan feltet skal
indekseres. En streng, der er gemt i et \texttt{Field} betegnes en
'\texttt{Term}'. Identiske strenge der er gemt i forskellige
\texttt{Fields} bliver betragtet som forskellige termer.

\subsection{Lucene \texttt{Index} struktur}
Et lucene \texttt{Document} kan indeholde:

\begin{itemize}
\item \texttt{Field} navne
\item Gemte \texttt{Field} værdier (gennem \texttt{Field.Store})
\item En \texttt{Term} \textit{dictionary}
\item \texttt{Term} frekvens data
\item \texttt{Term} afstandsdata (se afsnit \ref{sec:proximity})
\item Normaliseringsfaktorer
\item \texttt{Term} vectorer 

  \texttt{Term} vektorer bliver tilføjet gennem \texttt{Field`3},
  \texttt{Field`5} eller \texttt{Field`7} konstruktøren
  \footnote{\url{http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc//org/apache/lucene/document/Field.html}}
\item Slettede dokumenter
\end{itemize}

\subsubsection{\texttt{Term} vektorer}
\texttt{Term} vektorer understøtter muligheden for at lave "`Relevans
feedback"' og "`mere som dette"' iterationer over søgninger. Hvis der
er blevet givet offset information med termerne, kan der også laves
term highlighting i fremsøgningsresultaterne.

\subsection{Inverteret indeks}
Et inverteret indeks (Inverted index) er et indeks der, for en giver
term\footnote{her brugt i den generiske betydning, uden sammenhæng i
  øvrigt med \texttt{org.apache.lucene.index.Term}} viser hvilke
dokumenter der indeholder termen.

\subsection{Sub-indeks (segmenter)}
Et indeks kan opbygges af sub-indekser, i lucene kaldet
\texttt{segments}. Et segment fungerer som et uafhængigt indeks og kan
søges separat af det indeks det er indeholdt i. Dette kan have
betydning for søgetider på større indeks eller i indeks, der
indeholder meget store tekstmængder.

\subsection{Nummerering (internt)}
Lucene refererer til sine \texttt{Documents} med et \texttt{integer}
dokumentnummer. Dokumentnummeret bliver inkrementeret med en for hvert
indeks der gemmes og der kan derfor opstå 'huller' i nummereringen
hvis indeks slettes.

\subsection{Payloads}
Optimering af hvordan indekseringen gemmer felter i forhold til
hvordan fremsøgningen skal ske;
\url{http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc/org/apache/lucene/index/Payload.html}

\subsection{Updatering af \texttt{Document}s i Lucene indeks}
Lucene har ingen funktionalitet for at lave ændringer i enkelte
dokumenter i et indeks. Alle opdateringer til et \texttt{Document}
foregår som en sletning og indsætning i stedet. En opdatering består
derfor i at:

\begin{enumerate}
\item lokalisere det specifikke \texttt{Document}
\item slette det givne \texttt{Document}
\item oprette en opdateret version af dokumentet, og
\item insætte det opdaterede \texttt{Document} i indekset.
\end{enumerate}

For en stor mængde ændringer i dokumenter kan det performancemæssigt
være en fordel at batche skrivningerne af indekserne, hvis der
samtidigt bliver taget højde for i hvor høj grad indekserne skal være
up-to-date.

\subsection{(I/O) Operationer på Lucene indeks }
Lucene tillader simultan skrivning til og læsning fra indeks. Det skal
bemærkes, at søgning i (læsning af) et indeks sker på en statisk
udgave af det pågældende indeks, således at skrivninger der foretages
under søgningen ikke vil træde i kraft før efter læsningen er
afsluttet. Man kan bruge \texttt{IndexReader}ens \texttt{isCurrent}
metode for at teste om der er sket opdateringer til det indeks man
læser fra.

I/O operationer er generelt set noget af det dyreste at foretage sig i
lucene, typisk når man skriver indeks til disken. En lucene
\texttt{IndexWriter} kan tilpasses til at skrive sine indeks til RAM
og 'flushe' dem til disken med passende frekvens. 

\section{Søgning}
Søgning i lucene indeks kan fortages gennem flere forskellige metoder i \texttt{org.apache.lucene.search}. De mest simple er 
\begin{itemize}
\item \texttt{TermQuery}
\item \texttt{PhraseQuery}
\item \texttt{BooleanQuery}
\end{itemize}

Og i øvrigt findes:

\begin{itemize}
\item \texttt{MultiTermQuery}
\item \texttt{WildcardQuery}
\item \texttt{PrefixQuery}
\item \texttt{MultiPhraseQuery}
\item \texttt{FuzzyQuery}
\item \texttt{RangeQuery}
\item \texttt{SpanQuery} 
\end{itemize}

Som udgangspunkt konstruerer konstruktøren en \texttt{Query} ud fra
genstandsfeltet (\texttt{Term} for en \texttt{TermQuery} eller
\texttt{MultiTermQuery} \&c.). En \texttt{BooleanQuery} opererer på
flere \texttt{TermQuery} instanser og en \texttt{PhraseQuery} opererer
på sekvenser af \texttt{Term} instanser.

\label{sec:searchoptions}

Som nævnt i afsnit \ref{sec:anasoeg} vil der typisk blive brugt den
samme analyseringsmetode for indeksering og søgning for at kunne give
fremsøgningsresultater der er i overensstemmelse med det indekserede
materiale.

\section{\textit{Scoring}}

\subsection{\textit{Vector Space Model}}

\subsection{\textit{Boolean Model}}




\section{Bemærkninger}
I frobindelse med brugen af lucene er der nogle områder, det kan være
værd at være opmærksom på. I det følgende vil der blive behandlet
områder der kan have indflydelse på hvad implemetationer, der bygger
på lucene skal tage højde for.

\subsection{QueryParser er ikke trådsikker}
\url{http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc/org/apache/lucene/queryParser/QueryParser.html}. Gad
vide om det betyder noget?



% \section{Generel information}
% \subsection{Lucene bruger modified UTF-8 som tegnsæt}

% Ligesom java bruger lucene \textit{modified UTF-8} som intern
% repræsentation af strenge. Dette vil umiddelbart ikke have nogen
% konsekvenser for hvordan ens strenge bliver behandlet (medmindre
% \texttt{null}-karakteren tillægges sproglig værdi i det materiale der
% skal indekseres eller man bruger tekster hvis encoding udelukkende
% ligger i UTF-16). Dog er det vigtigt at være opmærksom på at
% tegnsættet for data bliver angivet korrekt i udvekslinger til og fra
% lucene\footnote{Se også Java teknologidokumentet i
%   \url{svn://svn.dbc.dk/OpenSearch/trunk/projekt_information/} og
%   \url{http://java.sun.com/javase/6/docs/api/java/io/DataInput.html#modified-utf-8}}.

\section{Links}
\begin{itemize}
   \item http://hudson.zones.apache.org/hudson/job/Lucene-trunk/javadoc/
   \item http://java.sun.com/javase/6/docs/api/java/io/DataInput.html\#modified-utf-8
   \item http://lucene.apache.org/java/2\_3\_2/fileformats.html\#Overview
   \item http://www.nist.gov/dads/HTML/invertedIndex.html
   \item http://en.wikipedia.org/wiki/Inverted\_index
   \item http://www.getopt.org/luke/
\end{itemize}

\end{document}
